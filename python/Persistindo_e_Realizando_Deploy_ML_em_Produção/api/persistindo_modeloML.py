# -*- coding: utf-8 -*-
"""Persistindo-modeloML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dNBSuQ8q9gIoqL3Y0ljNs-HTTs3FqGVq
"""

from sklearn.model_selection import train_test_split # importa método train_test_split. Existem outros como: K-Folds cross-validator
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import numpy as np
import pandas as pd

!wget https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/diabetes.csv

dados = pd.read_csv("diabetes.csv")

"""# Análise exploratória dos dados

https://minerandodados.com.br/analise-exploratoria-de-dados-passo-a-passo-com-python/

<br>Analisar/Selecionar Features/Campos, colunas, atributos - 
<br>como selecionar - https://minerandodados.com.br/aprenda-como-selecionar-features-para-seu-modelo-de-machine-learning/
<br> Algumas Features (Features não informativas) pode adicionar ruído ao modelo
"""

dados.head()

dados.shape

dados["Glucose"]

dados.info()

dados["Glucose"].unique()

# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html
# Retorne uma série contendo contagens de linhas exclusivas no DataFrame.
dados.Glucose.value_counts()

dados2 = dados[dados.Outcome ==1]  #mostra todos os registros cujo o OutCome seja igual 1
#dados2 = dados[dados.Outcome ==1].sample(5)
dados2

# verifica se existem campos/features/atributos vazios - checando Missing Values
dados2.isnull().sum()

#https://datatofish.com/replace-nan-values-with-zeros/
# Preencher as colunas NaN - não definida
# ou .fill('Yes') ou .fillna(data['colunax'].mean())
dados['Outcome'] = dados['Outcome'].fillna('0')

# chegar novamente Missing Value
dados.isnull().sum()

"""#Transformandos dados categóricos"""

from sklearn.preprocessing import LabelEncoder

#colunax_values = {'Female':0,'Male':1}
#coluna_casado_values = {'No':0,'Yes':1}
# dados.replace({'colunax':colunax_values, 'coluna_casado':coluna_casado_values}, inplace=True)
# exemplo
## OutCome_values = {'Yes':1,'No':0}
## dados2.replace({'OutCome': OutCome_values},inplace=True)

"""# Dividir o conjunto de dados em duas variáveis X e y"""

# X mantém os dados que a árvore de decisão vai usar para aprender e y são os rótulos.
features = dados.drop(["Outcome"], axis=1) #Excluir a coluna de resultado
X = np.array(features)  # dados
y = np.array(dados["Outcome"])  #rótulos

features.columns # verificar que a coluna Outcome foi excluída

"""# Dividir dos dados para Treinamento e Testes/Validação"""

# Divide o conjunto de dados com a seguinte função scikit-learn
# Usamos 20% (0.20) do conjunto de dados para construir o conjunto de validação.
# retorn uma tupla
# random_state=0 = Seed
X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.20)

"""#Selecionar o melhor classificado através de Pipeline e GridSearchCV"""

# Classificador Árvore de decisão
arvore = DecisionTreeClassifier(min_samples_leaf=10, max_depth=8, min_samples_split=50)

clf = arvore.fit(X_train, y_train) # método fit faz o treinamento do modelo
clf

from sklearn import tree
tree.plot_tree(clf)  # Existem outros modelos de apresentação

arvore.tree_.max_depth

# Usaremos o conjunto de validação para medir o desempenho do modelo
validation_prediction = arvore.predict(X_val)
training_prediction   = arvore.predict(X_train)

# from sklearn.metrics import accuracy_score
print('Accuracy training set: ', accuracy_score(y_true=y_train, y_pred=training_prediction))
print('Accuracy validation set: ', accuracy_score(y_true=y_val, y_pred=validation_prediction))

print(metrics.classification_report(y_val,clf.predict(X_val)))

"""# Persistindo o Modelo em disco"""

from sklearn.externals import  joblib

joblib.dump( arvore,'modelo.pkl'  )   #tira da Ram e salva no disco- joblib.dump

!ls

import pickle
with open('modelo2.pkl', 'wb') as f:
    pickle.dump(clf, f)

!ls

# carregando o modelo do disco para a memória usando a ferramenta joblib
model = joblib.load('modelo.pkl')

# carregando o modelo do disco para a memória com pickle
with open('modelo2.pkl', 'rb') as f:
    model2 = pickle.load(f)

# Verificando os atributos do modelo

print("Atributos do modelo:\n\nClasses:{}\n\nParamestros:{}".format(model.classes_,model.get_params))

# Teste de Classificação - Após treinamento e gerado o modelo

meus_dados = np.array([[6,148,72,35,0,33.6,0.627,50]])
model.predict(meus_dados)

#Probabilidade de Classes

model.predict_proba(meus_dados)

#Obs- mostra a probabilidade de ser 13% para classe 0 e 86% para a classe 1

model2.predict_proba(meus_dados)

"""# Flask"""

! pip install flask-ngrok

from flask_ngrok import run_with_ngrok 
from flask import Flask

app = Flask(__name__)
run_with_ngrok (app) #starts ngrok quando o aplicativo é executado
@ app.route ("/") 
def home (): 
    return "<h1> Executando Flask no Google Colab! </h1>"

app.run ()



"""....

# Outro classificador

##Selecionando o classificado RandomForest
"""

from sklearn.ensemble import RandomForestClassifier

#n_estimator= 100 - gerar 100 árvores
clf_rf = RandomForestClassifier(n_estimators=100, min_samples_split=2)

# Divide o conjunto de dados com a seguinte função scikit-learn
# Usamos 20% (0.20) do conjunto de dados para construir o conjunto de validação.
# retorn uma tupla
# random_state=0 = Seed
X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, test_size=0.30)

clf_rf.fit(X_train,y_train)

"""#Métricas de Validação"""

from sklearn import  metrics
from sklearn.model_selection import  train_test_split

# Métrica nos dados de Validação
# pd.crosstab = tabela cruzada de dois ou mais fatores
cross_table = pd.crosstab(y_train, clf_rf.predict(X_train), rownames=['Actual'], colnames=['Predicted'], margins=True)

cross_table

# Observer que acertou 100% - teve um overfitting - decorou os dados

# # Métrica nos dados de testes
cross_table = pd.crosstab(y_val, clf_rf.predict(X_val), rownames=['Actual'], colnames=['Predicted'], margins=True)
cross_table

# Analisando:  de 99 acertou 78 errou 21; de 55 acertou 36 e errou 19

print(metrics.classification_report(y_val,clf_rf.predict(X_val)))

# Usaremos o conjunto de validação para medir o desempenho do modelo
validation_prediction = clf_rf.predict(X_val)
training_prediction   = clf_rf.predict(X_train)

# from sklearn.metrics import accuracy_score
print('Accuracy training set: ', accuracy_score(y_true=y_train, y_pred=training_prediction))
print('Accuracy validation set: ', accuracy_score(y_true=y_val, y_pred=validation_prediction))